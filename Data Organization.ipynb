{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relelvent packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "data = pd.read_pickle('arxiv_fulldataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.789907e+06\n",
       "mean     4.166603e+00\n",
       "std      2.042236e+01\n",
       "min      1.000000e+00\n",
       "25%      2.000000e+00\n",
       "50%      3.000000e+00\n",
       "75%      4.000000e+00\n",
       "max      2.832000e+03\n",
       "Name: num_authors, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#avg number of authors per paper\n",
    "num_authors = [len(ls) for ls in data.authors_parsed]\n",
    "data['num_authors'] = num_authors\n",
    "data.num_authors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 4 authors per paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "authors_new = [[re.sub('[^a-z]', '', (author[0] + author[1]).lower()) for author in ls] for ls in data.authors_parsed]\n",
    "assert(len(authors_new) == len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['authors_cleaned'] = authors_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [[Bal√°zs, C., ], [Berger, E. L., ], [Nadolsky,...\n",
       "1              [[Streinu, Ileana, ], [Theran, Louis, ]]\n",
       "2                                    [[Pan, Hongjun, ]]\n",
       "3                                   [[Callan, David, ]]\n",
       "4     [[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]\n",
       "5                     [[Pong, Y. H., ], [Law, C. K., ]]\n",
       "6     [[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...\n",
       "7                                [[Swift, Damian C., ]]\n",
       "8     [[Harvey, Paul, ], [Merin, Bruno, ], [Huard, T...\n",
       "9                             [[Ovchinnikov, Sergei, ]]\n",
       "10      [[Cunningham, Clifton, ], [Dembele, Lassina, ]]\n",
       "11                                   [[Choi, Dohoon, ]]\n",
       "12               [[Choi, Dohoon, ], [Choie, YoungJu, ]]\n",
       "13                                  [[Fujii, Koichi, ]]\n",
       "14                               [[Stahn, Christian, ]]\n",
       "15    [[Chang, Chao-Hsi, ], [Li, Tong, ], [Li, Xue-Q...\n",
       "16    [[Mhlahlo, Nceba, ], [Buckley, David H., ], [D...\n",
       "17                            [[Gustavsson, Andreas, ]]\n",
       "18                                   [[Konno, Norio, ]]\n",
       "19      [[The BABAR Collaboration, , ], [Aubert, B., ]]\n",
       "Name: authors_parsed, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['authors_parsed'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                [balzsc, bergerel, nadolskypm, yuancp]\n",
       "1                          [streinuileana, theranlouis]\n",
       "2                                          [panhongjun]\n",
       "3                                         [callandavid]\n",
       "4                  [abushammalawael, torchinskyalberto]\n",
       "5                                       [pongyh, lawck]\n",
       "6     [corichialejandro, vukasinactatjana, zapatajosea]\n",
       "7                                        [swiftdamianc]\n",
       "8     [harveypaul, merinbruno, huardtracyl, rebulllu...\n",
       "9                                   [ovchinnikovsergei]\n",
       "10                  [cunninghamclifton, dembelelassina]\n",
       "11                                         [choidohoon]\n",
       "12                           [choidohoon, choieyoungju]\n",
       "13                                        [fujiikoichi]\n",
       "14                                     [stahnchristian]\n",
       "15        [changchaohsi, litong, lixueqian, wangyuming]\n",
       "16    [mhlahlonceba, buckleydavidh, dhillonvikrams, ...\n",
       "17                                  [gustavssonandreas]\n",
       "18                                         [konnonorio]\n",
       "19                     [thebabarcollaboration, aubertb]\n",
       "Name: authors_cleaned, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['authors_cleaned'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit Abstracts\n",
    "from analysis we know most articles are around 200 words\n",
    "\n",
    "there are 176 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of all categories used\n",
    "categories = list(data.categories.str.split(' '))\n",
    "num_categories = [len(ls) for ls in categories]\n",
    "categories_ls = [category for ls in categories for category in ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(categories_ls) == sum(num_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    }
   ],
   "source": [
    "#get set of unique categories used\n",
    "categories_set = set(categories_ls)\n",
    "print(len(categories_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#theoretical categories set from the ArXiv taxonomy page\n",
    "categories_theor = 'cs.AI, cs.AR, cs.CC, cs.CE, cs.CG, cs.CL, cs.CR, cs.CV, cs.CY, cs.DB, cs.DC, cs.DL, cs.DM, cs.DS, cs.ET, cs.FL, cs.GL, cs.GR, cs.GT, cs.HC, cs.IR, cs.IT, cs.LG, cs.LO, cs.MA, cs.MM, cs.MS, cs.NA, cs.NE, cs.NI, cs.OH, cs.OS, cs.PF, cs.PL, cs.RO, cs.SC, cs.SD, cs.SE, cs.SI, cs.SY, econ.EM, econ.GN, econ.TH, eess.AS, eess.IV, eess.SP, eess.SY, math.AC, math.AG, math.AP, math.AT, math.CA, math.CO, math.CT, math.CV, math.DG, math.DS, math.FA, math.GM, math.GN, math.GR, math.GT, math.HO, math.IT, math.KT, math.LO, math.MG, math.MP, math.NA, math.NT, math.OA, math.OC, math.PR, math.QA, math.RA, math.RT, math.SG, math.SP, math.ST, astro-ph.CO, astro-ph.EP, astro-ph.GA, astro-ph.HE, astro-ph.IM, astro-ph.SR, cond-mat.dis-nn, cond-mat.mes-hall, cond-mat.mtrl-sci, cond-mat.other, cond-mat.quant-gas, cond-mat.soft, cond-mat.stat-mech, cond-mat.str-el, cond-mat.supr-con, gr-qc, hep-ex, hep-lat, hep-ph, hep-th, math-ph, nlin.AO, nlin.CD, nlin.CG, nlin.PS, nlin.SI, nucl-ex, nucl-th, physics.acc-ph, physics.ao-ph, physics.app-ph, physics.atm-clus, physics.atom-ph, physics.bio-ph, physics.chem-ph, physics.class-ph, physics.comp-ph, physics.data-an, physics.ed-ph, physics.flu-dyn, physics.gen-ph, physics.hist-ph, physics.ins-det, physics.med-ph, physics.optics, physics.plasm-ph, physics.pop-ph, physics.soc-ph, physics.space-ph, quant-ph, q-bio.BM, q-bio.CB, q-bio.GN, q-bio.MN, q-bio.NC, q-bio.OT, q-bio.PE, q-bio.QM, q-bio.SC, q-bio.TO, q-fin.CP, q-fin.EC, q-fin.GN, q-fin.MF, q-fin.PM, q-fin.PR, q-fin.RM, q-fin.ST, q-fin.TR, stat.AP, stat.CO, stat.ME, stat.ML, stat.OT, stat.TH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of occurences of each category\n",
    "value_counts = sorted([[category, categories_ls.count(category)] for category in categories_set], key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['math.MP', 63403],\n",
       " ['math-ph', 63403],\n",
       " ['cond-mat.mtrl-sci', 67384],\n",
       " ['cs.LG', 68953],\n",
       " ['cond-mat.mes-hall', 70691],\n",
       " ['gr-qc', 84649],\n",
       " ['astro-ph', 105380],\n",
       " ['quant-ph', 107920],\n",
       " ['hep-th', 140204],\n",
       " ['hep-ph', 153126]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([1636693, 1638090, 1637995])\n",
    "data.to_pickle('abstract.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Table with Authors and their paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_array = np.array([data.id, data.authors_cleaned]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_dict = {}\n",
    "for article in authors_array:\n",
    "    ID = article[0]\n",
    "    for author in article[1]:\n",
    "        if author in authors_dict.keys():\n",
    "            authors_dict[author].append(ID)\n",
    "        else:\n",
    "            authors_dict[author] = [ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_array = np.array([data.categories, data.authors_cleaned]).T\n",
    "category_dict = {}\n",
    "for article in authors_array:\n",
    "    cat = article[0]\n",
    "    cat = re.split('\\s+', cat)\n",
    "    for author in article[1]:\n",
    "        if author in category_dict.keys():\n",
    "            category_dict[author].extend(cat)\n",
    "        else:\n",
    "            category_dict[author] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in category_dict.items():\n",
    "    newvalue = list(set(value))\n",
    "    category_dict[key] = newvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_data = pd.DataFrame()\n",
    "authors_data['Authors'] = authors_dict.keys()\n",
    "authors_data['Articles'] = authors_dict.values()\n",
    "authors_data['Categories'] = category_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_data['Num_Articles'] = [len(articles) for articles in authors_data.Articles]\n",
    "authors_data['Num_Categories'] = [len(categories) for categories in authors_data.Categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_data.to_pickle('authors.pkl')\n",
    "#data.to_pickle('abstract.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Author Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_array = np.array([data.id, data.authors_cleaned]).T\n",
    "authors_dict = {}\n",
    "for article in authors_array:\n",
    "    ID = article[0]\n",
    "    cycle = len(article[1])\n",
    "    i = 0\n",
    "    for author in article[1]:\n",
    "        for i in range(cycle):\n",
    "            if author == article[1][i]:\n",
    "                continue\n",
    "            elif article[1][i] in authors_dict.keys():\n",
    "                addon = set(authors_dict[article[1][i]])\n",
    "                addon.add(author)\n",
    "                authors_dict[article[1][i]] = list(addon)\n",
    "            else:\n",
    "                authors_dict[article[1][i]] = [author]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_graph = pd.DataFrame()\n",
    "authors_graph['Authors'] = authors_dict.keys()\n",
    "authors_graph['Collaborators'] = authors_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref = authors_graph.T.to_dict(orient='list') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nodes = {v[0]:v[1] for k, v in data_ref.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1069645"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "G = nx.from_dict_of_lists(dict_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 1069645\n",
      "Number of edges: 42624678\n",
      "Average degree:  79.6987\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(G,\"AuthorGraph.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
